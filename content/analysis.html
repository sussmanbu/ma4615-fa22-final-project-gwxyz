---
title: Analysis
description:
toc: true
featuredVideo:
featuredImage: /images/nba_analysis.png
draft: false
---


<div id="TOC">

</div>

<div id="motivation-and-initial-questions" class="section level2">
<h2>Motivation and Initial Questions</h2>
<p>abc</p>
</div>
<div id="important-variable-in-nba" class="section level2">
<h2>Important Variable in NBA</h2>
<p><img src="/analysis_files/figure-html/unnamed-chunk-2-1.png" width="672" />
The graph shows that SAS had a higher steal mean and median than MEM and CHA. That might contribute to winning the championship.</p>
<p><br></p>
<p><img src="/analysis_files/figure-html/unnamed-chunk-3-1.png" width="672" />
Most of the players in SAS assisted more than the other two team players did, which made AST an important criteria for winning the championship. </p>
<p><br></p>
<p><img src="/analysis_files/figure-html/unnamed-chunk-4-1.png" width="672" />
Players in SAS had a relatively higher VORP than other players. Many of them earned 3, while players in CHA and MEM earned only about 0 and 1. It clearly shows that there are more valuable players in SAS, and that may be why it winned the championship.</p>
<p><br></p>
<p><img src="/analysis_files/figure-html/unnamed-chunk-5-1.png" width="672" />
In 2016, the 3 points percentage mean and median were higher for players in CLE than in BOS and OKC, which made 3P% a useful index to be evaluated.</p>
<p><br></p>
<p><img src="/analysis_files/figure-html/unnamed-chunk-6-1.png" width="672" />
This bar chart shows the average steals for each team in the 2013-2014 playoffs. We can see the champion team SAS get the second greatest average steals, which shows the average level of the SAS players is high this year. This also proves to us that STL is an important variable in our model.</p>
<p><br></p>
<p><img src="/analysis_files/figure-html/unnamed-chunk-7-1.png" width="672" />
This bar chart shows the average assists for each team in the 2013-2014 playoffs. The champion team SAS got the second greatest average assists, which also proves to us that AST is an important variable in our consideration.</p>
<p><br></p>
<p><img src="/analysis_files/figure-html/unnamed-chunk-8-1.png" width="672" />
This bar chart shows the average value over placement player for each team in the 2013-2014 playoffs. The champion team SAS got the third greatest average value over placement player, which means that the players in that team this year are very good and valuable, and that also shows us that VORP is an important variable in our consideration.</p>
<p><br></p>
<p><img src="/analysis_files/figure-html/unnamed-chunk-9-1.png" width="672" />
This chart presents the average blocked shots of Playoffs teams in 2014-2015. The champion GSW also gets a higher blocked shots than most of the other teams.</p>
<p><br></p>
</div>
<div id="modeling" class="section level2">
<h2>Modeling</h2>
<p>In this model section, our goal is trying to predict the chance of each NBA team winning the 2017 championship based on variables we believed that has the most significant contribution to a team’s competence. To be able to making the most reliable model and prediction, we decide to use the most recent 3 year’s data from every team for our analysis, which takes many considerations into the account, including changes in player’s style, intensity of defense, rules of calls and other factors that made big difference between now day’s NBA and earlier time. In order to find out strongest predictor variables, we used AIC method to investigate the significance of every variables of our interest. After the predictor variables have been determined, we then made the logistic regression that has predictor variables and the response variables which is 1 and 0 indicating whether the team we are interested in made into playoffs each year. We then used the model we made to make a prediction with year of 2017 and came up with a table of winning index for every team in 2017. Lastly we compared the team who has the highest winning index with the actual championship of 2017 and make our conclusion.</p>
<pre><code>## 
## Call:  glm(formula = playoff ~ mean_age + mean_stl + mean_ast + mean_blk + 
##     mean_3p, family = &quot;binomial&quot;, data = combine4)
## 
## Coefficients:
## (Intercept)     mean_age     mean_stl     mean_ast     mean_blk      mean_3p  
##    -6.00907      0.22325     -0.07496      0.01245      0.07793     -1.02168  
## 
## Degrees of Freedom: 30 Total (i.e. Null);  25 Residual
## Null Deviance:       42.94 
## Residual Deviance: 41.63     AIC: 53.63</code></pre>
<pre><code>## 
## Call:
## glm(formula = playoff ~ mean_age + mean_stl + mean_ast + mean_blk + 
##     mean_3p, family = &quot;binomial&quot;, data = combine4)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -1.535  -1.170   0.855   1.076   1.541  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept) -6.00907    7.14359  -0.841    0.400
## mean_age     0.22325    0.27041   0.826    0.409
## mean_stl    -0.07496    0.12108  -0.619    0.536
## mean_ast     0.01245    0.04443   0.280    0.779
## mean_blk     0.07793    0.09718   0.802    0.423
## mean_3p     -1.02168    9.40927  -0.109    0.914
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 42.943  on 30  degrees of freedom
## Residual deviance: 41.635  on 25  degrees of freedom
## AIC: 53.635
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p><img src="/analysis_files/figure-html/unnamed-chunk-10-1.png" width="672" />
For 2014, our AIC model has given us the best predictors with the lowest AIC value of 53.63. these variables are: Player’s age, steal, assist,block and three points. however, for our logistic regression, these predictors has no significant contribution to our desire model, so 2014 data may not be our best candidates for our prediction model.
The ROC-AUC Curve tells how good our model is and based on the AUC value( 0.625), we believe that our model has moderate accuracy for the prediction.</p>
<p><br></p>
<pre><code>## 
## Call:
## glm(formula = playoff ~ mean_age + mean_stl + mean_ast + mean_blk, 
##     family = &quot;binomial&quot;, data = combine5)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -1.635  -1.072   0.355   1.034   1.710  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)  
## (Intercept) -3.97059    7.75200  -0.512   0.6085  
## mean_age     0.15855    0.29763   0.533   0.5942  
## mean_stl    -0.19647    0.11485  -1.711   0.0871 .
## mean_ast     0.09010    0.05253   1.715   0.0863 .
## mean_blk    -0.10906    0.11812  -0.923   0.3558  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 42.943  on 30  degrees of freedom
## Residual deviance: 37.890  on 26  degrees of freedom
## AIC: 47.89
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p><img src="/analysis_files/figure-html/unnamed-chunk-11-1.png" width="672" />
With 2015’s data, we got the best predictor variables(age, steal, assist, block) from AIC method and this time the AIC drops to 47.89. our logistic regression showed that assist and steal are significant predictors variable but the rest of predictors are still remain insignificant. The ROC-AUC Curve is better than 2014’s model with the AUC value of 0.717. So we believe that this model also has moderate accuracy for the prediction and is a better choice than 2014’s prediction model.</p>
<p><br></p>
<pre><code>## Start:  AIC=36.38
## playoff ~ mean_per + mean_trb + mean_ast + mean_blk + mean_3p + 
##     mean_age + mean_G + mean_stl + mean_tov + mean_ows + mean_vorp + 
##     mean_ws + mean_pf + mean_fg + mean_ts
## 
##             Df Deviance    AIC
## - mean_ows   1   1.9611 34.399
## - mean_G     1   1.9611 34.400
## - mean_ws    1   1.9645 34.453
## - mean_trb   1   1.9657 34.472
## - mean_ts    1   1.9726 34.580
## - mean_fg    1   1.9850 34.774
## - mean_tov   1   1.9937 34.910
## - mean_vorp  1   1.9942 34.918
## - mean_ast   1   2.0228 35.360
## - mean_per   1   2.0460 35.713
## - mean_stl   1   2.0745 36.143
## &lt;none&gt;           1.9602 36.384
## - mean_pf    1   2.0933 36.421
## - mean_age   1   2.1226 36.852
## - mean_3p    1   2.2224 38.277
## - mean_blk   1   2.2348 38.449
## 
## Step:  AIC=34.4
## playoff ~ mean_per + mean_trb + mean_ast + mean_blk + mean_3p + 
##     mean_age + mean_G + mean_stl + mean_tov + mean_vorp + mean_ws + 
##     mean_pf + mean_fg + mean_ts
## 
##             Df Deviance    AIC
## - mean_G     1   1.9614 32.404
## - mean_ws    1   1.9668 32.489
## - mean_trb   1   1.9710 32.555
## - mean_ts    1   1.9751 32.619
## - mean_vorp  1   1.9944 32.921
## - mean_tov   1   1.9969 32.961
## - mean_fg    1   2.0151 33.242
## - mean_ast   1   2.0229 33.360
## - mean_per   1   2.0513 33.793
## &lt;none&gt;           1.9611 34.399
## - mean_pf    1   2.0938 34.429
## - mean_stl   1   2.1172 34.773
## - mean_age   1   2.1226 34.852
## - mean_3p    1   2.2228 36.283
## - mean_blk   1   2.2418 36.547
## 
## Step:  AIC=32.4
## playoff ~ mean_per + mean_trb + mean_ast + mean_blk + mean_3p + 
##     mean_age + mean_stl + mean_tov + mean_vorp + mean_ws + mean_pf + 
##     mean_fg + mean_ts
## 
##             Df Deviance    AIC
## - mean_ws    1   1.9670 30.492
## - mean_trb   1   1.9718 30.567
## - mean_ts    1   1.9769 30.649
## - mean_vorp  1   1.9961 30.947
## - mean_tov   1   2.0003 31.013
## - mean_ast   1   2.0311 31.486
## - mean_fg    1   2.0320 31.500
## - mean_per   1   2.0527 31.815
## &lt;none&gt;           1.9614 32.404
## - mean_pf    1   2.0943 32.436
## - mean_age   1   2.1304 32.966
## - mean_stl   1   2.1314 32.981
## - mean_3p    1   2.2233 34.289
## - mean_blk   1   2.2507 34.669
## 
## Step:  AIC=30.49
## playoff ~ mean_per + mean_trb + mean_ast + mean_blk + mean_3p + 
##     mean_age + mean_stl + mean_tov + mean_vorp + mean_pf + mean_fg + 
##     mean_ts
## 
##             Df Deviance    AIC
## - mean_trb   1   1.9782 28.668
## - mean_ts    1   1.9833 28.748
## - mean_tov   1   2.0004 29.014
## - mean_ast   1   2.0311 29.487
## - mean_fg    1   2.0339 29.530
## - mean_per   1   2.0530 29.818
## &lt;none&gt;           1.9670 30.492
## - mean_pf    1   2.1070 30.624
## - mean_stl   1   2.1343 31.023
## - mean_age   1   2.1566 31.345
## - mean_blk   1   2.2516 32.681
## - mean_3p    1   2.3205 33.615
## - mean_vorp  1   3.6798 47.909
## 
## Step:  AIC=28.67
## playoff ~ mean_per + mean_ast + mean_blk + mean_3p + mean_age + 
##     mean_stl + mean_tov + mean_vorp + mean_pf + mean_fg + mean_ts
## 
##             Df Deviance    AIC
## - mean_tov   1   2.0004 27.014
## - mean_ts    1   2.0071 27.118
## - mean_fg    1   2.0526 27.813
## - mean_ast   1   2.0643 27.989
## &lt;none&gt;           1.9782 28.668
## - mean_per   1   2.1108 28.680
## - mean_pf    1   2.1469 29.206
## - mean_age   1   2.1671 29.495
## - mean_stl   1   2.1696 29.531
## - mean_blk   1   2.3055 31.415
## - mean_3p    1   2.4235 32.962
## - mean_vorp  1   3.8036 46.935
## 
## Step:  AIC=27.01
## playoff ~ mean_per + mean_ast + mean_blk + mean_3p + mean_age + 
##     mean_stl + mean_vorp + mean_pf + mean_fg + mean_ts
## 
##             Df Deviance    AIC
## - mean_ts    1   2.0338 25.528
## - mean_fg    1   2.0901 26.373
## - mean_ast   1   2.0929 26.415
## - mean_per   1   2.1276 26.926
## &lt;none&gt;           2.0004 27.014
## - mean_pf    1   2.1481 27.223
## - mean_stl   1   2.1704 27.543
## - mean_age   1   2.2012 27.979
## - mean_blk   1   2.3958 30.606
## - mean_3p    1   2.6472 33.700
## - mean_vorp  1   4.1079 47.321
## 
## Step:  AIC=25.53
## playoff ~ mean_per + mean_ast + mean_blk + mean_3p + mean_age + 
##     mean_stl + mean_vorp + mean_pf + mean_fg
## 
##             Df Deviance    AIC
## - mean_fg    1   2.1067 24.619
## - mean_per   1   2.1287 24.941
## - mean_ast   1   2.1485 25.229
## - mean_pf    1   2.1572 25.354
## &lt;none&gt;           2.0338 25.528
## - mean_stl   1   2.1909 25.835
## - mean_age   1   2.2226 26.279
## - mean_blk   1   2.3959 28.607
## - mean_3p    1   2.6965 32.271
## - mean_vorp  1   4.2409 46.309
## 
## Step:  AIC=24.62
## playoff ~ mean_per + mean_ast + mean_blk + mean_3p + mean_age + 
##     mean_stl + mean_vorp + mean_pf
## 
##             Df Deviance    AIC
## - mean_pf    1   2.1579 23.364
## - mean_per   1   2.1933 23.868
## &lt;none&gt;           2.1067 24.619
## - mean_age   1   2.2940 25.260
## - mean_stl   1   2.3123 25.506
## - mean_ast   1   2.4910 27.814
## - mean_blk   1   2.5157 28.119
## - mean_3p    1   2.7085 30.409
## - mean_vorp  1   4.3125 44.827
## 
## Step:  AIC=23.36
## playoff ~ mean_per + mean_ast + mean_blk + mean_3p + mean_age + 
##     mean_stl + mean_vorp
## 
##             Df Deviance    AIC
## - mean_per   1   2.2469 22.617
## &lt;none&gt;           2.1579 23.364
## - mean_age   1   2.3429 23.914
## - mean_stl   1   2.4006 24.668
## - mean_ast   1   2.4932 25.841
## - mean_blk   1   2.5291 26.284
## - mean_3p    1   2.7794 29.210
## - mean_vorp  1   4.4490 43.793
## 
## Step:  AIC=22.62
## playoff ~ mean_ast + mean_blk + mean_3p + mean_age + mean_stl + 
##     mean_vorp
## 
##             Df Deviance    AIC
## &lt;none&gt;           2.2469 22.617
## - mean_age   1   2.4424 23.203
## - mean_stl   1   2.4711 23.566
## - mean_ast   1   2.5019 23.950
## - mean_blk   1   2.8611 28.108
## - mean_3p    1   3.0357 29.945
## - mean_vorp  1   4.7114 43.570</code></pre>
<pre><code>## 
## Call:
## glm(formula = playoff ~ mean_age + mean_stl + mean_ast + mean_blk + 
##     mean_3p, family = &quot;binomial&quot;, data = combine6)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.4034  -0.7746  -0.0805   0.5740   2.7159  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)  
## (Intercept) -48.75805   19.25080  -2.533   0.0113 *
## mean_age      1.35176    0.61207   2.208   0.0272 *
## mean_stl      0.36524    0.19514   1.872   0.0612 .
## mean_ast     -0.06588    0.07378  -0.893   0.3719  
## mean_blk     -0.16573    0.16749  -0.990   0.3224  
## mean_3p      34.87594   16.65645   2.094   0.0363 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 42.943  on 30  degrees of freedom
## Residual deviance: 27.416  on 25  degrees of freedom
## AIC: 39.416
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p><img src="/analysis_files/figure-html/unnamed-chunk-12-1.png" width="672" />
For 2016’s data, we showed our AIC steps for better visualization of how we end up with our best predictors. Our AIC value dropped to 22.62 with predictor variables: age, steal, assist,block, three point and Value over Placement Player. Our logistic regression has shown multiple significant predictors and a strong ROC-AUC Curve model with the AUC value of 0.896. So we believed this will be the best candidate model for us to make the final prediction.</p>
<p><br></p>
<pre><code>##     Tm Winning_index
## 1  SAS     0.9983127
## 2  GSW     0.9864207
## 3  LAC     0.9834590
## 4  CLE     0.9715875
## 5  SAC     0.9582206
## 6  HOU     0.9313386
## 7  MEM     0.9116486
## 8  WAS     0.8825779
## 9  TOT     0.8220494
## 10 ATL     0.8147579
## 11 IND     0.7937216
## 12 BOS     0.7826239
## 13 DAL     0.7513338
## 14 MIN     0.7505512
## 15 OKC     0.6948686
## 16 DET     0.6759130</code></pre>
</div>
<div id="model" class="section level2">
<h2>Model</h2>
<p>We made a logistic regression that uses six most important variables as the predictor variables and we set response variables to 1 and 0 indicating whether the team we are interested in makes the playoffs. We then can use the model we made to make a prediction with another year that we are interested in and compare the result whether the champion that we predicted matches the actual championship of that year. The ROC-AUC Curve tells how good our model is and based on the AUC value( 0.708), we believe that our model has certain accuracy for predicting based on the variables we chose.</p>
</div>
<div id="explanation" class="section level2">
<h2>Explanation</h2>
<p>Lastly, we made our prediction on every NBA team’s chance of winning the 2017 championship, the label winning index indicate the likelyhood of that team winning the champ and the table shows the top 16 teams winning index.</p>
</div>
<div id="conclusion" class="section level2">
<h2>Conclusion</h2>
<p>Our goal is to use playoff data in 2014, 2015, and 2016 to estimate the champion for 2017, and compare with the actual champion in 2017. We use histograms and density lines to analyze which factors have influence on winning a champion. We find that TS%, AST, PTS, BLK, and 3P% are the main factors. Based on this finding, we calculate the mean of each factor for each team, and create a logistic model to estimate the probability of winning the championship for that particular team. Teams that have the probabilities larger than 0.5 are considered as more likely to make into the playoffs, and the team with the largest probability will win the championship based on our prediction.</p>
</div>
<div id="further-evaulation" class="section level2">
<h2>Further Evaulation</h2>
<p>We analyze different positions using corresponding factors and come up with a “Dream Team” by choosing top 1 in each position to form the starting line-up and choosing second place in each position to form the substitute bench.
Point Guard is responsible for assist, passer and ball handler. Who are expected to have exceptional passing skills, ball-handling skills, make assists and play good defense against the opposing point guard. And are often valued more for their assist totals than for their scoring. So we choose “AST” to analyze “Point Guard”
Shooting Guard’s main objective is to score points for their team and steal the ball on defense. Who are known for making shots from beyond the three-point line and being one of the primary players responsible for stealing balls on defense. So we choose “3PA” to analyze “Shooting Guard”.
Small Forward is responsible for scoring points and defending, and often are secondary or tertiary rebounders behind the power forward and center. So we choose “PTS” to analyze “Small Forward”.
Power Forward is responsible for rebounding, blocking shots and defending the post, and occasionally shooting. So we choose “BLK” to analyze “Power Forward”.
Center is the most important position, as he is the last line of defense against people driving towards the basket. And they are responsible for close shots and rebounds on offense and try to block opponents’ shots and rebound their misses on defense. So we choose “ORB” to analyze “Center”.</p>
<p>Starting-Lineup
Point Guard: PG - Stephen Curry
Shooting Guard: SG - Klay Tompson
Small Forward: SF - Lebron James
Power Forward: PF - Serge Ibaka
Center: C - Dwight Howard
Substitute Bench
Point Guard: PG - Russell Westbrook
Shooting Guard: SG - James Harden
Small Forward: SF - Kevin Durant
Power Forward: PF - Draymond Green
Center: C - Hassan Whiteside</p>
<p>Point Guard: PG - Stephen Curry, Russell Westbrook</p>
<pre class="r"><code>playoffs %&gt;% filter(Tm%in%c(&quot;IND&quot;, &quot;SAS&quot;, &quot;MIA&quot;, &quot;OKC&quot;,&quot;GSW&quot;, &quot;CLE&quot;, &quot;HOU&quot;, &quot;ATL&quot;, &quot;BOS&quot;)) %&gt;% filter(Pos == &quot;PG&quot;) %&gt;% 
  ggplot() +
  stat_summary(aes(x = AST, y = PlayerName), fun = mean, geom = &quot;bar&quot;)</code></pre>
<p><img src="/analysis_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>Shooting Guard: SG - Klay Tompson, James Harden</p>
<pre class="r"><code>playoffs %&gt;% filter(Tm%in%c(&quot;IND&quot;, &quot;SAS&quot;, &quot;MIA&quot;, &quot;OKC&quot;,&quot;GSW&quot;, &quot;CLE&quot;, &quot;HOU&quot;, &quot;ATL&quot;, &quot;BOS&quot;)) %&gt;% filter(Pos == &quot;SG&quot;) %&gt;% 
  ggplot() +
  stat_summary(aes(x = `3PA`, y = PlayerName), fun = mean, geom = &quot;bar&quot;)</code></pre>
<p><img src="/analysis_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>Small Forward: SF - Lebron James, Kevin Durant</p>
<pre class="r"><code>playoffs %&gt;% filter(Tm%in%c(&quot;IND&quot;, &quot;SAS&quot;, &quot;MIA&quot;, &quot;OKC&quot;,&quot;GSW&quot;, &quot;CLE&quot;, &quot;HOU&quot;, &quot;ATL&quot;, &quot;BOS&quot;)) %&gt;% filter(Pos == &quot;SF&quot;) %&gt;% 
  ggplot() +
  stat_summary(aes(x = PTS, y = PlayerName), fun = mean, geom = &quot;bar&quot;)</code></pre>
<p><img src="/analysis_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>Power Forward: PF - Serge Ibaka, Draymond Green</p>
<pre class="r"><code>playoffs %&gt;% filter(Tm%in%c(&quot;IND&quot;, &quot;SAS&quot;, &quot;MIA&quot;, &quot;OKC&quot;,&quot;GSW&quot;, &quot;CLE&quot;, &quot;HOU&quot;, &quot;ATL&quot;, &quot;BOS&quot;)) %&gt;% filter(Pos == &quot;PF&quot;) %&gt;% 
  ggplot() +
  stat_summary(aes(x = BLK, y = PlayerName), fun = mean, geom = &quot;bar&quot;)</code></pre>
<p><img src="/analysis_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>Center: C - Dwight Howard, Hassan Whiteside</p>
<pre class="r"><code>playoffs %&gt;% filter(Tm%in%c(&quot;IND&quot;, &quot;SAS&quot;, &quot;MIA&quot;, &quot;OKC&quot;,&quot;GSW&quot;, &quot;CLE&quot;, &quot;HOU&quot;, &quot;ATL&quot;, &quot;BOS&quot;)) %&gt;% filter(Pos == &quot;C&quot;) %&gt;% 
  ggplot() +
  stat_summary(aes(x = ORB, y = PlayerName), fun = mean, geom = &quot;bar&quot;)</code></pre>
<p><img src="/analysis_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
</div>
<div id="rubric-on-this-page" class="section level2">
<h2>Rubric: On this page</h2>
<p>you will</p>
<ul>
<li>Introduce what motivates your Data Analysis (DA)
<ul>
<li>Which variables and relationships are you most interested in?</li>
<li>What questions are you interested in answering?</li>
</ul></li>
<li>Breadth of the DA
<ul>
<li>Make sure that you ask enough initial questions to explore the different variables in your data.</li>
<li>i.e. Do you explore more than just one or two variables? Do you explore a few different relationships or many?</li>
</ul></li>
<li>Depth of the DA
<ul>
<li>When you answer one question, usually more questions arise as well.</li>
<li>The depth of the DA is about coming up with and exploring the answers to these questions, often iterating the process a few times.</li>
</ul></li>
<li>Modeling and Inference
<ul>
<li>You should also include some kind of formal statistical model and/or inference. This could be a linear regression, logistic regression, hypothesis testing etc.</li>
<li>Explain the techniques you used for validating your results.</li>
<li>Describe the results of your modelling and make sure to give a sense of the uncertainty in your estimates and conclusions.</li>
</ul></li>
<li>Explain the flaws and limitations of your analysis
<ul>
<li>Are there some assumptions that you needed to make that might not hold? Is there other data that would help to answer your questions? …</li>
</ul></li>
<li>Clarity Figures
<ul>
<li>Are your figures/tables/results easy to read, informative, without problems like overplotting, hard-to-read labels, etc?</li>
<li>Each figure should provide a key insight. Too many figures or other data summaries can detract from this.</li>
</ul></li>
<li>Clarity of Explanations
<ul>
<li>Do you introduce why you are doing each analysis?</li>
<li>How well do you explain each figure/result?</li>
<li>Do you provide interpretations that suggest further analysis or explanations for observed phenomenon?</li>
</ul></li>
<li>Organization and cleanliness.
<ul>
<li>Make sure to remove excessive warnings, use clean easy-to-read code, organize with sections or multiple pages, use bullets, etc.</li>
</ul></li>
</ul>
<p><strong>NOTE</strong>: Your Data Analysis can be broken up into multiple pages if that helps with your organization.</p>
</div>
